{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/a1/273def87037a7fb010512bbc5901c31cfddfca8080bc63b42b26e3cc55b3/scikit_learn-0.23.2-cp36-cp36m-manylinux1_x86_64.whl (6.8MB)\n",
      "\u001b[K     |████████████████████████████████| 6.8MB 7.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scipy>=0.19.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8a/14/d0475ceeaa047f3eae2dc7597c3d40228e1d5beee42c1730f3c96ffb5526/scipy-1.5.3-cp36-cp36m-manylinux1_x86_64.whl (25.9MB)\n",
      "\u001b[K     |████████████████████████████████| 25.9MB 39.1MB/s eta 0:00:01�█████▎             | 14.8MB 39.1MB/s eta 0:00:01MB 39.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting joblib>=0.11\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/c9/f58220ac44a1592f79a343caba12f6837f9e0c04c196176a3d66338e1ea8/joblib-0.17.0-py3-none-any.whl (301kB)\n",
      "\u001b[K     |████████████████████████████████| 307kB 40.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy>=1.13.3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/97/af8a92864a04bfa48f1b5c9b1f8bf2ccb2847f24530026f26dd223de4ca0/numpy-1.19.2-cp36-cp36m-manylinux2010_x86_64.whl (14.5MB)\n",
      "\u001b[K     |████████████████████████████████| 14.5MB 19.5MB/s eta 0:00:01�███████████████▌            | 8.8MB 19.5MB/s eta 0:00:01     |███████████████████████████████▍| 14.2MB 19.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
      "Installing collected packages: numpy, scipy, joblib, threadpoolctl, scikit-learn\n",
      "Successfully installed joblib-0.17.0 numpy-1.19.2 scikit-learn-0.23.2 scipy-1.5.3 threadpoolctl-2.1.0\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a2/21/e10d65222d19a2537e3eb0df306686a9eabd08b3c98dd120e43720bf802d/pandas-1.1.3-cp36-cp36m-manylinux1_x86_64.whl (9.5MB)\n",
      "\u001b[K     |████████████████████████████████| 9.5MB 12.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.15.4 in /opt/app-root/lib/python3.6/site-packages (from pandas) (1.19.2)\n",
      "Collecting pytz>=2017.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4f/a4/879454d49688e2fad93e59d7d4efda580b783c745fd2ec2a3adf87b0808d/pytz-2020.1-py2.py3-none-any.whl (510kB)\n",
      "\u001b[K     |████████████████████████████████| 512kB 34.0MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /opt/app-root/lib/python3.6/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/app-root/lib/python3.6/site-packages (from python-dateutil>=2.7.3->pandas) (1.13.0)\n",
      "Installing collected packages: pytz, pandas\n",
      "Successfully installed pandas-1.1.3 pytz-2020.1\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/47/f8ef524e15ff86f5246cb4e1cee200b747ddb2536429fa021cc5f17ea40a/lightgbm-3.0.0-py2.py3-none-manylinux1_x86_64.whl (1.7MB)\n",
      "\u001b[K     |████████████████████████████████| 1.8MB 10.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/app-root/lib/python3.6/site-packages (from lightgbm) (1.19.2)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in /opt/app-root/lib/python3.6/site-packages (from lightgbm) (0.23.2)\n",
      "Requirement already satisfied: scipy in /opt/app-root/lib/python3.6/site-packages (from lightgbm) (1.5.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/app-root/lib/python3.6/site-packages (from scikit-learn!=0.22.0->lightgbm) (0.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/app-root/lib/python3.6/site-packages (from scikit-learn!=0.22.0->lightgbm) (2.1.0)\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-3.0.0\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test_data, model_name, clf):\n",
    "    from sklearn import metrics\n",
    "    y_pred=clf.predict(test_data)\n",
    "    print(f\"prediction: {y_pred}\")\n",
    "    # AUC\n",
    "    print(f\"auc: {metrics.roc_auc_score(y_test, y_pred)}\")\n",
    "    # convert probabilities to binary prediction using threshold=0.5\n",
    "    for i in range(0,y_pred.shape[0]):\n",
    "        if y_pred[i]>=.5: # setting threshold to .5\n",
    "            y_pred[i]=1\n",
    "        else:\n",
    "            y_pred[i]=0\n",
    "    # Confusion matrix\n",
    "    cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "    print(f\"Confusion matrix:\\n {cm}\")\n",
    "    # Accuracy\n",
    "    accuracy=metrics.accuracy_score(y_pred,y_test)\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    # Precision\n",
    "    precision = metrics.precision_score(y_pred,y_test, average='micro')\n",
    "    print(f\"Precision: {precision}\")\n",
    "    # Recall\n",
    "    recall = metrics.recall_score(y_pred,y_test, average='micro')\n",
    "    print(f\"Recall: {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 5479, number of negative: 17313\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001298 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 618\n",
      "[LightGBM] [Info] Number of data points in the train set: 22792, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240391 -> initscore=-1.150535\n",
      "[LightGBM] [Info] Start training from score -1.150535\n",
      "----------LightGBM--------------\n",
      "prediction: [0.02165759 0.02283388 0.1498168  ... 0.9988587  0.42303509 0.00596977]\n",
      "auc: 0.919577699974176\n",
      "Confusion matrix:\n",
      " [[6879  528]\n",
      " [ 827 1535]]\n",
      "Accuracy: 0.8612959361244754\n",
      "Precision: 0.8612959361244754\n",
      "Recall: 0.8612959361244754\n",
      "-----------END--------------\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearsvc',\n",
      "                 LinearSVC(C=0.001, dual=False, penalty='l1',\n",
      "                           random_state=42))])\n",
      "----------SVM--------------\n",
      "prediction: [0 0 0 ... 1 0 0]\n",
      "auc: 0.6631821661707059\n",
      "Confusion matrix:\n",
      " [[7162  245]\n",
      " [1513  849]]\n",
      "Accuracy: 0.8200429931415703\n",
      "Precision: 0.8200429931415703\n",
      "Recall: 0.8200429931415703\n",
      "-----------END--------------\n"
     ]
    }
   ],
   "source": [
    "#Adult Census Income Binary classfication dataset\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/habtamu/demo/main/dataset.csv')\n",
    "new_df = df.loc[:, ~df.columns.isin([' workclass',' occupation',' native-country'])]\n",
    "le = LabelEncoder()\n",
    "new_df.loc[:,' education'] = le.fit_transform(new_df.loc[:,' education'].values.tolist())\n",
    "new_df.loc[:,' marital-status'] = le.fit_transform(new_df.loc[:,' marital-status'].values.tolist())\n",
    "new_df.loc[:,' relationship'] = le.fit_transform(new_df.loc[:,' relationship'].values.tolist())\n",
    "new_df.loc[:,' race'] = le.fit_transform(new_df.loc[:,' race'].values.tolist())\n",
    "new_df.loc[:,' sex'] = le.fit_transform(new_df.loc[:,' sex'].values.tolist())\n",
    "new_df.loc[:,' income'] = le.fit_transform(new_df.loc[:,' income'].values.tolist())\n",
    "X = new_df.drop(' income', axis=1)\n",
    "y = new_df[' income']\n",
    "\n",
    "#use stratify for un balanced number of examples for each class label\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                        test_size=0.3,\n",
    "                                                        #stratify=y,\n",
    "                                                        random_state=0)\n",
    "\n",
    "# Experiment 1: using Boosted Decision Tree [LightGBM]\n",
    "import lightgbm as lgb\n",
    "MODEL = 'LightGBM'\n",
    "d_train = lgb.Dataset(X_train, label=y_train)\n",
    "params = {}\n",
    "params['learning_rate'] = 0.2\n",
    "params['boosting_type'] = 'gbdt'\n",
    "params['objective'] = 'binary'\n",
    "params['metric'] = 'auc'\n",
    "params['num_leaves'] = 20\n",
    "params['min_data'] = 10\n",
    "#params['max_depth'] = 10\n",
    "#params['sub_feature'] = 0.5\n",
    "\n",
    "# data is ready to train\n",
    "clf = lgb.train(params, d_train, 100)\n",
    "# predict\n",
    "print(f\"----------{MODEL}--------------\")\n",
    "predict(X_test, model_name=MODEL, clf=clf)\n",
    "print(f\"-----------END--------------\")\n",
    "\n",
    "# Experiment 2: using Support Vector Machines\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "MODEL = 'SVM'\n",
    "clf = make_pipeline(StandardScaler(), \n",
    "                    LinearSVC(penalty='l1', C=0.001, dual=False, max_iter=1000, random_state=42))\n",
    "#clf = make_pipeline(StandardScaler(), SVC(C=0.001, kernel='linear', random_state=42))\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf)\n",
    "    \n",
    "# predict\n",
    "print(f\"----------{MODEL}--------------\")\n",
    "predict(X_test, model_name=MODEL, clf=clf)\n",
    "print(f\"-----------END--------------\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
