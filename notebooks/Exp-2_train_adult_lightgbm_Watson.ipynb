{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Adults Census Model Training with IBM Watson Machine Learning  \n",
    "## LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "\n",
    "1. Data Preparation\n",
    "2. Model Training\n",
    "3. Model Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python libraries that we'll use throughout the analysis\n",
    "import os\n",
    "import types\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from botocore.client import Config\n",
    "import ibm_boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>IncomeGroup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt   education  education-num  \\\n",
       "0   39          State-gov   77516   Bachelors             13   \n",
       "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
       "2   38            Private  215646     HS-grad              9   \n",
       "3   53            Private  234721        11th              7   \n",
       "4   28            Private  338409   Bachelors             13   \n",
       "\n",
       "        marital-status          occupation    relationship    race      sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week  native-country IncomeGroup  \n",
       "0          2174             0              40   United-States       <=50K  \n",
       "1             0             0              13   United-States       <=50K  \n",
       "2             0             0              40   United-States       <=50K  \n",
       "3             0             0              40   United-States       <=50K  \n",
       "4             0             0              40            Cuba       <=50K  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n",
    "# You might want to remove those credentials before you share the notebook.\n",
    "client = ibm_boto3.client(service_name='s3',\n",
    "                          ibm_api_key_id='7rULUuPgOFK63b96NYtJ9q1SzM16E4cyWVeUCIg-ukte',\n",
    "                          ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n",
    "                          config=Config(signature_version='oauth'),\n",
    "endpoint_url='https://s3-api.us-geo.objectstorage.service.networklayer.com')\n",
    "\n",
    "body = client.get_object(Bucket='adultscensusproject-donotdelete-pr-7nekr9yeith2lc',Key='adult.csv')['Body']\n",
    "df = pd.read_csv(body)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class= <=50K, Count=34014, Percentage=75.216%\n",
      "Class= >50K, Count=11208, Percentage=24.784%\n"
     ]
    }
   ],
   "source": [
    "# summarize the class distribution\n",
    "import collections\n",
    "\n",
    "target = df.values[:,-1]\n",
    "counter = collections.Counter(target)\n",
    "for k,v in counter.items():\n",
    "    per = v / len(target) * 100\n",
    "    print('Class=%s, Count=%d, Percentage=%.3f%%' % (k, v, per))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Downloading lightgbm-3.1.1-py2.py3-none-manylinux1_x86_64.whl (1.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.8 MB 20.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn!=0.22.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from lightgbm) (0.23.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from lightgbm) (1.5.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from lightgbm) (1.18.5)\n",
      "Requirement already satisfied: wheel in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from lightgbm) (0.34.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from scikit-learn!=0.22.0->lightgbm) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from scikit-learn!=0.22.0->lightgbm) (0.16.0)\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-3.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: WML Notebook Instance\n",
      "\n",
      "Last updated: 2020-12-09\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.7.9\n",
      "IPython version      : 7.15.0\n",
      "\n",
      "numpy                      : 1.18.5\n",
      "pandas                     : 1.0.5\n",
      "scipy                      : 1.5.0\n",
      "sklearn                    : 0.23.1\n",
      "lightgbm                   : 3.1.1\n",
      "ibm_boto3                  : 2.7.0\n",
      "botocore                   : 1.16.11\n",
      "ibm_watson_machine_learning: 1.0.43\n",
      "\n",
      "Compiler    : GCC 7.3.0\n",
      "OS          : Linux\n",
      "Release     : 4.15.0-122-generic\n",
      "Machine     : x86_64\n",
      "Processor   : x86_64\n",
      "CPU cores   : 56\n",
      "Architecture: 64bit\n",
      "\n",
      "Hostname: notebook-conda1py3725f880f6ada9447e8629ea063173a606-54c7956bhrd\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%reload_ext watermark\n",
    "%watermark  -d -u -h -m -a \"WML Notebook Instance\" -v -p numpy,pandas,scipy,sklearn,lightgbm,ibm_boto3,botocore,ibm_watson_machine_learning\n",
    "\n",
    "# The runtime has 1 vCPU and 4 GB RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python libraries \n",
    "import time\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and evaluate a model\n",
    "def train_evaluate_model(features, model_suffix):\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    print('building datasets')\n",
    "    target = 'IncomeGroup'\n",
    "    X = df[features.split()]\n",
    "    y = df[target]\n",
    "\n",
    "    # label encode the target variable to have the classes 0 and 1\n",
    "    y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "    cat_ix = X.select_dtypes(include=['object', 'bool']).columns\n",
    "    print(f\"cat_ix: {cat_ix}\")\n",
    "    num_ix = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "    print(f\"num_ix: {num_ix}\")\n",
    "\n",
    "    #use stratify for un balanced number of examples for each class label\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=42,shuffle=True)\n",
    "    print(f\"X_train:{X_train.shape}\")\n",
    "    print(f\"X_test: {X_test.shape}\")\n",
    "    print(f\"y_train:{y_train.shape}\")\n",
    "    print(f\"y_test: {y_test.shape}\")\n",
    "\n",
    "\n",
    "    # Model Training: gbdt\n",
    "    print('training model')\n",
    "    MODEL = \"gbdt\"\n",
    "    # set training parameters\n",
    "    params = {\n",
    "        \"boosting_type\":'gbdt',     # boosting type, support gbdt for now, alias: boosting, boost\n",
    "        \"objective\": \"binary\",      # binary , binary classification task\n",
    "        \"learning_rate\": 0.2,       # shrinkage rate\n",
    "        \"n_estimators\":  100,       # n_estimators (int, optional (default=100)) – Number of boosted trees to fit.\n",
    "        \"num_leaves\": 20,           # number of leaves for one tree\n",
    "        \"min_child_samples\": 10,    # min_child_samples (int, optional (default=20)) – Minimum number of data needed in a child (leaf).\n",
    "        \"metric\": \"binary_logloss\", # binary_logloss , default metric for binary\n",
    "        \"random_state\": 42\n",
    "    }\n",
    "\n",
    "    model = LGBMClassifier(boosting_type = params[\"boosting_type\"],\n",
    "                           objective = params[\"objective\"],\n",
    "                           learning_rate = params[\"learning_rate\"],                  \n",
    "                           num_leaves = params[\"num_leaves\"], \n",
    "                           min_child_samples = params[\"min_child_samples\"],\n",
    "                           metric = params[\"metric\"],\n",
    "                           random_state = params[\"random_state\"],\n",
    "                           n_estimators = params[\"n_estimators\"])\n",
    "    # define steps\n",
    "    steps = [('c',OneHotEncoder(handle_unknown='ignore'),cat_ix), ('n',MinMaxScaler(),num_ix)]\n",
    "    # one hot encode categorical, normalize numerical\n",
    "    ct = ColumnTransformer(steps)\n",
    "    # wrap the model a pipeline\n",
    "    pipe  = Pipeline(steps=[('transformer',ct),('gbdt',model)])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    print(f\"model: {pipe}\")\n",
    "\n",
    "    ## Evaluate the model\n",
    "    # using threshold\n",
    "    threshold = 0.5 # set threshold as 0.5\n",
    "    y_pred = (pipe.predict_proba(X_test)[:,1] >= threshold).astype(int) \n",
    "    print(f\"y_pred: {y_pred}\")\n",
    "    print(f'Misclassified examples:{(y_test != y_pred).sum()}')\n",
    "    print(pipe.predict_proba(X_test))\n",
    "\n",
    "    print(f\"distinct y_pred: {np.unique(y_pred)}\")\n",
    "    print(f\"distinct y_test: {np.unique(y_test)}\")\n",
    "\n",
    "    # Confusion Matrix\n",
    "    conf_mat = metrics.confusion_matrix(y_test, y_pred)\n",
    "    print(f\"confusion matrix:\\n {conf_mat}\")\n",
    "\n",
    "    # AUC\n",
    "    auc = metrics.roc_auc_score(y_test, y_pred)\n",
    "    print(f\"auc: {auc}\")\n",
    "\n",
    "    # Accuracy\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy: {accuracy}\") \n",
    "\n",
    "    # Precision\n",
    "    precision = metrics.precision_score(y_test, y_pred)\n",
    "    print(f\"Precision: {precision}\")\n",
    "\n",
    "    # Recall\n",
    "    recall = metrics.recall_score(y_test, y_pred)\n",
    "    print(f\"Recall: {recall}\")\n",
    "\n",
    "    # F1\n",
    "    f1 = metrics.f1_score(y_test, y_pred)\n",
    "    print(f\"F1: {f1}\")\n",
    "\n",
    "    # classification_report\n",
    "    print('classification_report')\n",
    "    print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "    # persist model\n",
    "    joblib.dump(pipe, f\"{MODEL}_{model_suffix}.joblib\")\n",
    "    client.upload_file(Filename=f\"{MODEL}_{model_suffix}.joblib\",\n",
    "                   Bucket='adultscensusproject-donotdelete-pr-7nekr9yeith2lc',\n",
    "                   Key=f\"{MODEL}_{model_suffix}.joblib\")\n",
    "    \n",
    "    time_elapsed = (time.time() - start_time)\n",
    "    print(\"Computational time:{}\".format(time_elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building datasets\n",
      "cat_ix: Index(['education', 'marital-status', 'relationship', 'race', 'sex'], dtype='object')\n",
      "num_ix: Index(['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss',\n",
      "       'hours-per-week'],\n",
      "      dtype='object')\n",
      "X_train:(31655, 11)\n",
      "X_test: (13567, 11)\n",
      "y_train:(31655,)\n",
      "y_test: (13567,)\n",
      "training model\n",
      "model: Pipeline(steps=[('transformer',\n",
      "                 ColumnTransformer(transformers=[('c',\n",
      "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
      "                                                  Index(['education', 'marital-status', 'relationship', 'race', 'sex'], dtype='object')),\n",
      "                                                 ('n', MinMaxScaler(),\n",
      "                                                  Index(['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss',\n",
      "       'hours-per-week'],\n",
      "      dtype='object'))])),\n",
      "                ('gbdt',\n",
      "                 LGBMClassifier(learning_rate=0.2, metric='binary_logloss',\n",
      "                                min_child_samples=10, num_leaves=20,\n",
      "                                objective='binary', random_state=42))])\n",
      "y_pred: [1 0 0 ... 0 0 0]\n",
      "Misclassified examples:1870\n",
      "[[0.39897098 0.60102902]\n",
      " [0.87132    0.12868   ]\n",
      " [0.92701237 0.07298763]\n",
      " ...\n",
      " [0.82981225 0.17018775]\n",
      " [0.55009492 0.44990508]\n",
      " [0.52011085 0.47988915]]\n",
      "distinct y_pred: [0 1]\n",
      "distinct y_test: [0 1]\n",
      "confusion matrix:\n",
      " [[9539  654]\n",
      " [1216 2158]]\n",
      "auc: 0.787717619010594\n",
      "Accuracy: 0.8621655487580158\n",
      "Precision: 0.767425320056899\n",
      "Recall: 0.6395969176052163\n",
      "F1: 0.697704494018752\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91     10193\n",
      "           1       0.77      0.64      0.70      3374\n",
      "\n",
      "    accuracy                           0.86     13567\n",
      "   macro avg       0.83      0.79      0.80     13567\n",
      "weighted avg       0.86      0.86      0.86     13567\n",
      "\n",
      "Computational time:1125.4179019927979\n"
     ]
    }
   ],
   "source": [
    "# Result 1\n",
    "model_suffix = \"exp1\"\n",
    "features = 'age fnlwgt education education-num marital-status relationship race sex capital-gain capital-loss hours-per-week'\n",
    "train_evaluate_model(features, model_suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building datasets\n",
      "cat_ix: Index(['workclass', 'education', 'marital-status', 'occupation',\n",
      "       'relationship', 'race', 'sex', 'native-country'],\n",
      "      dtype='object')\n",
      "num_ix: Index(['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss',\n",
      "       'hours-per-week'],\n",
      "      dtype='object')\n",
      "X_train:(31655, 14)\n",
      "X_test: (13567, 14)\n",
      "y_train:(31655,)\n",
      "y_test: (13567,)\n",
      "training model\n",
      "model: Pipeline(steps=[('transformer',\n",
      "                 ColumnTransformer(transformers=[('c',\n",
      "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
      "                                                  Index(['workclass', 'education', 'marital-status', 'occupation',\n",
      "       'relationship', 'race', 'sex', 'native-country'],\n",
      "      dtype='object')),\n",
      "                                                 ('n', MinMaxScaler(),\n",
      "                                                  Index(['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss',\n",
      "       'hours-per-week'],\n",
      "      dtype='object'))])),\n",
      "                ('gbdt',\n",
      "                 LGBMClassifier(learning_rate=0.2, metric='binary_logloss',\n",
      "                                min_child_samples=10, num_leaves=20,\n",
      "                                objective='binary', random_state=42))])\n",
      "y_pred: [0 0 0 ... 0 0 0]\n",
      "Misclassified examples:1745\n",
      "[[0.53570775 0.46429225]\n",
      " [0.90555827 0.09444173]\n",
      " [0.92430793 0.07569207]\n",
      " ...\n",
      " [0.7814943  0.2185057 ]\n",
      " [0.60741851 0.39258149]\n",
      " [0.68615902 0.31384098]]\n",
      "distinct y_pred: [0 1]\n",
      "distinct y_test: [0 1]\n",
      "confusion matrix:\n",
      " [[9583  610]\n",
      " [1135 2239]]\n",
      "auc: 0.8018795195815019\n",
      "Accuracy: 0.8713790815950468\n",
      "Precision: 0.7858897858897859\n",
      "Recall: 0.6636040308239478\n",
      "F1: 0.7195886228507151\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.92     10193\n",
      "           1       0.79      0.66      0.72      3374\n",
      "\n",
      "    accuracy                           0.87     13567\n",
      "   macro avg       0.84      0.80      0.82     13567\n",
      "weighted avg       0.87      0.87      0.87     13567\n",
      "\n",
      "Computational time:1106.4066586494446\n"
     ]
    }
   ],
   "source": [
    "# Result 2\n",
    "model_suffix = \"exp2\"\n",
    "features = 'age workclass fnlwgt education education-num marital-status occupation relationship race sex capital-gain capital-loss hours-per-week native-country'\n",
    "train_evaluate_model(features, model_suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
