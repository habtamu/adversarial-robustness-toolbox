2020/11/20 22:19:06 Attempt 1 of http call to http://10.0.0.4:16384/sendlogstoartifacts/info
2020/11/20 22:19:06 Attempt 1 of http call to http://10.0.0.4:16384/sendlogstoartifacts/status
[2020-11-20T22:19:08.028962] Entering context manager injector.
[context_manager_injector.py] Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'Dataset:context_managers.Datasets', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError'], invocation=['urldecode_invoker.py', 'python', '-m', 'azureml.studio.modulehost.module_invoker', '--module-name=azureml.studio.modules.ml.score.score_generic_module.score_generic_module', '--scored-dataset', 'DatasetOutputConfig:Scored_dataset', '--trained-model=DatasetConsumptionConfig:Trained_model', '--dataset=DatasetConsumptionConfig:Dataset', '--append-score-columns-to-output=True'])
Initialize DatasetContextManager.
WARNING - Already registered authentication for run id: 9f97ea91-32b6-460f-8594-4d4f6e91163e
Script type = None
Starting the daemon thread to refresh tokens in background for process with pid = 101
Set Dataset Trained_model's target path to /tmp/tmpz6nw9_hr
Set Dataset Dataset's target path to /tmp/tmpsr_c8lwa
Enter __enter__ of DatasetContextManager
SDK version: azureml-core==1.15.0 azureml-dataprep==2.2.5. Session id: f4b4afc0-c419-4d42-9cbd-cceca2e34949. Run id: 9f97ea91-32b6-460f-8594-4d4f6e91163e.
Processing 'Trained_model'.
Processing dataset FileDataset
{
  "source": [
    "('workspaceblobstore', 'azureml/385a3b33-ed94-4fb7-a4f9-c0ed71ace290/Trained_model')"
  ],
  "definition": [
    "GetDatastoreFiles"
  ],
  "registration": {
    "id": "5a6977c1-0405-4464-a6a9-1ad7da3c4db6",
    "name": null,
    "version": null,
    "workspace": "Workspace.create(name='unive-workspace', subscription_id='79dab02c-2ae9-417c-ab9d-ca9bdf3a29c5', resource_group='unive-resource-group')"
  }
}
Mounting Trained_model to /tmp/tmpz6nw9_hr.
Mounted Trained_model to /tmp/tmpz6nw9_hr as folder.
Processing 'Dataset'.
Processing dataset FileDataset
{
  "source": [
    "('workspaceblobstore', 'azureml/6cf18974-2e55-4230-b726-e846e2e81609/Results_dataset2')"
  ],
  "definition": [
    "GetDatastoreFiles"
  ],
  "registration": {
    "id": "8d733b4f-d36f-4a77-82bc-bbe5df4b982b",
    "name": null,
    "version": null,
    "workspace": "Workspace.create(name='unive-workspace', subscription_id='79dab02c-2ae9-417c-ab9d-ca9bdf3a29c5', resource_group='unive-resource-group')"
  }
}
Mounting Dataset to /tmp/tmpsr_c8lwa.
Mounted Dataset to /tmp/tmpsr_c8lwa as folder.
Processing 'Scored_dataset'.
Exit __enter__ of DatasetContextManager
Entering Run History Context Manager.
Current directory:  /mnt/batch/tasks/shared/LS_root/jobs/unive-workspace/azureml/9f97ea91-32b6-460f-8594-4d4f6e91163e/mounts/workspaceblobstore/azureml/9f97ea91-32b6-460f-8594-4d4f6e91163e
Preparing to call script [ urldecode_invoker.py ] with arguments: ['python', '-m', 'azureml.studio.modulehost.module_invoker', '--module-name=azureml.studio.modules.ml.score.score_generic_module.score_generic_module', '--scored-dataset', '$Scored_dataset', '--trained-model=$Trained_model', '--dataset=$Dataset', '--append-score-columns-to-output=True']
After variable expansion, calling script [ urldecode_invoker.py ] with arguments: ['python', '-m', 'azureml.studio.modulehost.module_invoker', '--module-name=azureml.studio.modules.ml.score.score_generic_module.score_generic_module', '--scored-dataset', '/tmp/tmp3oxa0ckd', '--trained-model=/tmp/tmpz6nw9_hr', '--dataset=/tmp/tmpsr_c8lwa', '--append-score-columns-to-output=True']

Session_id = f4b4afc0-c419-4d42-9cbd-cceca2e34949
Invoking module by urldecode_invoker 0.0.8.

Module type: official module.

Using runpy to invoke module 'azureml.studio.modulehost.module_invoker'.

2020-11-20 22:19:41,496 studio.modulehost    INFO       Reset logging level to DEBUG
2020-11-20 22:19:41,496 studio.modulehost    INFO       Load pyarrow.parquet explicitly: <module 'pyarrow.parquet' from '/azureml-envs/azureml_65af40e73c072fae369d0c087f7671ca/lib/python3.6/site-packages/pyarrow/parquet.py'>
2020-11-20 22:19:41,497 studio.core          INFO       execute_with_cli - Start:
2020-11-20 22:19:41,497 studio.modulehost    INFO       |   ALGHOST 0.0.140
2020-11-20 22:19:41,503 studio.modulehost    INFO       |   CLI arguments parsed: {'module_name': 'azureml.studio.modules.ml.score.score_generic_module.score_generic_module', 'OutputPortsInternal': {'Scored dataset': '/tmp/tmp3oxa0ckd'}, 'InputPortsInternal': {'Trained model': '/tmp/tmpz6nw9_hr', 'Dataset': '/tmp/tmpsr_c8lwa'}, 'ModuleParameters': {'Append score columns to output': 'True'}}
2020-11-20 22:19:41,505 studio.modulehost    INFO       |   Invoking ModuleEntry(azureml.studio.modules.ml.score.score_generic_module.score_generic_module; ScoreModelModule; run)
2020-11-20 22:19:41,505 studio.core          DEBUG      |   Input Ports:
2020-11-20 22:19:41,506 studio.core          DEBUG      |   |   Trained model = <azureml.studio.modulehost.cli_parser.CliInputValue object at 0x7f9f380f8668>
2020-11-20 22:19:41,506 studio.core          DEBUG      |   |   Dataset = <azureml.studio.modulehost.cli_parser.CliInputValue object at 0x7f9f380f8748>
2020-11-20 22:19:41,506 studio.core          DEBUG      |   Output Ports:
2020-11-20 22:19:41,506 studio.core          DEBUG      |   |   Scored dataset = /tmp/tmp3oxa0ckd
2020-11-20 22:19:41,506 studio.core          DEBUG      |   Parameters:
2020-11-20 22:19:41,507 studio.core          DEBUG      |   |   Append score columns to output = True
2020-11-20 22:19:41,508 studio.core          DEBUG      |   Environment Variables:
2020-11-20 22:19:41,508 studio.core          DEBUG      |   |   AZUREML_DATAREFERENCE_Trained_model = /tmp/tmpz6nw9_hr
2020-11-20 22:19:41,509 studio.core          DEBUG      |   |   AZUREML_DATAREFERENCE_Dataset = /tmp/tmpsr_c8lwa
2020-11-20 22:19:41,509 studio.core          INFO       |   Reflect input ports and parameters - Start:
2020-11-20 22:19:41,509 studio.core          INFO       |   |   Handle input port "Trained model" - Start:
2020-11-20 22:19:41,509 studio.core          INFO       |   |   |   Mount/Download dataset to '/tmp/tmpz6nw9_hr' - Start:
2020-11-20 22:19:41,509 studio.modulehost    DEBUG      |   |   |   |   Content of directory /tmp/tmpz6nw9_hr:
2020-11-20 22:19:42,126 studio.modulehost    DEBUG      |   |   |   |   |   _meta.yaml
2020-11-20 22:19:42,126 studio.modulehost    DEBUG      |   |   |   |   |   _samples.json
2020-11-20 22:19:42,126 studio.modulehost    DEBUG      |   |   |   |   |   _schema.json
2020-11-20 22:19:42,126 studio.modulehost    DEBUG      |   |   |   |   |   conda_env.yaml
2020-11-20 22:19:42,127 studio.modulehost    DEBUG      |   |   |   |   |   data.ilearner
2020-11-20 22:19:42,127 studio.modulehost    DEBUG      |   |   |   |   |   data.metadata
2020-11-20 22:19:42,127 studio.modulehost    DEBUG      |   |   |   |   |   data_type.json
2020-11-20 22:19:42,128 studio.modulehost    DEBUG      |   |   |   |   |   model_spec.yaml
2020-11-20 22:19:42,128 studio.modulehost    DEBUG      |   |   |   |   |   score.py
2020-11-20 22:19:42,128 studio.core          INFO       |   |   |   Mount/Download dataset to '/tmp/tmpz6nw9_hr' - End with 0.6196s elapsed.
2020-11-20 22:19:42,130 studio.core          INFO       |   |   |   Try to read from /tmp/tmpz6nw9_hr via meta - Start:
2020-11-20 22:19:42,778 studio.common        INFO       |   |   |   |   Load meta data from directory successfully, data=ModelDirectory(meta={'type': 'ModelDirectory', 'extension': {}, 'model': 'model_spec.yaml', 'registerModel': True, 'modelOutputPath': 'trained_model_outputs'}), type=<class 'azureml.studio.core.io.model_directory.ModelDirectory'>
2020-11-20 22:19:42,779 studio.common        INFO       |   |   |   |   Load ModelDirectory successfully, data=<azureml.studio.modules.ml.initialize_models.binary_classifier.boosted_decision_tree_biclassifier.boosted_decision_tree_biclassifier.BoostDecisionTreeBiClassifier object at 0x7f9f380f8c50>
2020-11-20 22:19:42,779 studio.core          INFO       |   |   |   Try to read from /tmp/tmpz6nw9_hr via meta - End with 0.6487s elapsed.
2020-11-20 22:19:42,779 studio.core          INFO       |   |   Handle input port "Trained model" - End with 1.2701s elapsed.
2020-11-20 22:19:42,779 studio.core          INFO       |   |   Handle input port "Dataset" - Start:
2020-11-20 22:19:42,779 studio.core          INFO       |   |   |   Mount/Download dataset to '/tmp/tmpsr_c8lwa' - Start:
2020-11-20 22:19:42,779 studio.modulehost    DEBUG      |   |   |   |   Content of directory /tmp/tmpsr_c8lwa:
2020-11-20 22:19:43,161 studio.modulehost    DEBUG      |   |   |   |   |   _meta.yaml
2020-11-20 22:19:43,161 studio.modulehost    DEBUG      |   |   |   |   |   _samples.json
2020-11-20 22:19:43,162 studio.modulehost    DEBUG      |   |   |   |   |   data.dataset
2020-11-20 22:19:43,162 studio.modulehost    DEBUG      |   |   |   |   |   data.dataset.parquet
2020-11-20 22:19:43,162 studio.modulehost    DEBUG      |   |   |   |   |   data.metadata
2020-11-20 22:19:43,162 studio.modulehost    DEBUG      |   |   |   |   |   data.schema
2020-11-20 22:19:43,162 studio.modulehost    DEBUG      |   |   |   |   |   data.visualization
2020-11-20 22:19:43,163 studio.modulehost    DEBUG      |   |   |   |   |   data_type.json
2020-11-20 22:19:43,216 studio.modulehost    DEBUG      |   |   |   |   |   schema/_schema.json
2020-11-20 22:19:43,217 studio.core          INFO       |   |   |   Mount/Download dataset to '/tmp/tmpsr_c8lwa' - End with 0.4375s elapsed.
2020-11-20 22:19:43,218 studio.core          INFO       |   |   |   Try to read from /tmp/tmpsr_c8lwa via meta - Start:
2020-11-20 22:19:44,152 studio.common        INFO       |   |   |   |   Load DataTableMeta successfully, path=data.dataset
2020-11-20 22:19:44,155 studio.common        INFO       |   |   |   |   Load meta data from directory successfully, data=DataFrameDirectory(meta={'type': 'DataFrameDirectory', 'visualization': [{'type': 'Visualization', 'path': 'data.visualization'}], 'extension': {'DataTableMeta': 'data.dataset'}, 'format': 'Parquet', 'data': 'data.dataset.parquet', 'samples': '_samples.json', 'schema': 'schema/_schema.json'}), type=<class 'azureml.studio.common.datatable.data_table_directory.DataTableDirectory'>
2020-11-20 22:19:44,156 studio.core          INFO       |   |   |   Try to read from /tmp/tmpsr_c8lwa via meta - End with 0.9369s elapsed.
2020-11-20 22:19:44,156 studio.core          INFO       |   |   Handle input port "Dataset" - End with 1.3766s elapsed.
2020-11-20 22:19:44,156 studio.modulehost    INFO       |   |   Parse bool parameter
2020-11-20 22:19:44,156 studio.core          INFO       |   Reflect input ports and parameters - End with 2.6473s elapsed.
2020-11-20 22:19:44,156 studio.core          INFO       |   ScoreModelModule.run - Start:
2020-11-20 22:19:44,156 studio.core          DEBUG      |   |   kwargs:
2020-11-20 22:19:44,156 studio.core          DEBUG      |   |   |   learner = <azureml.studio.modules.ml.initialize_models.binary_classifier.boosted_decision_tree_biclassifier.boosted_decision_tree_biclassifier.BoostDecisionTreeBiClassifier object at 0x7f9f380f8c50>
2020-11-20 22:19:44,156 studio.core          DEBUG      |   |   |   test_data = <azureml.studio.common.datatable.data_table.DataTable object at 0x7f9f380f8c18>
2020-11-20 22:19:44,156 studio.core          DEBUG      |   |   |   append_or_result_only = True
2020-11-20 22:19:44,157 studio.core          DEBUG      |   |   validated_args:
2020-11-20 22:19:44,157 studio.core          DEBUG      |   |   |   learner = <azureml.studio.modules.ml.initialize_models.binary_classifier.boosted_decision_tree_biclassifier.boosted_decision_tree_biclassifier.BoostDecisionTreeBiClassifier object at 0x7f9f380f8c50>
2020-11-20 22:19:44,157 studio.core          DEBUG      |   |   |   test_data = <azureml.studio.common.datatable.data_table.DataTable object at 0x7f9f380f8c18>
2020-11-20 22:19:44,157 studio.core          DEBUG      |   |   |   append_or_result_only = True
2020-11-20 22:19:44,158 studio.module        INFO       |   |   Validated testing data has 9768 Row(s) and 12 Columns.
2020-11-20 22:19:44,160 studio.module        INFO       |   |   Check if column types of test data are consistent with train data
2020-11-20 22:19:44,160 studio.module        INFO       |   |   Building Normalizer - found Label column=None with encode_label=False
2020-11-20 22:19:44,160 studio.module        INFO       |   |   Building normalizer - found 11 feature columns with normalize_number=True
2020-11-20 22:19:44,160 studio.module        DEBUG      |   |   Building normalizer - found feature columns: "age,fnlwgt,education,education-num,marital-status,relationship,race,sex,capital-gain,capital-loss,hours-per-week".
2020-11-20 22:19:44,161 studio.module        INFO       |   |   Building normalizer - found 11 numeric feature columns and 0 string feature columns to be encoded
2020-11-20 22:19:44,161 studio.module        DEBUG      |   |   Building normalizer - found numeric feature columns to be encoded: "age,fnlwgt,education,education-num,marital-status,relationship,race,sex,capital-gain,capital-loss,hours-per-week".
2020-11-20 22:19:44,161 studio.module        DEBUG      |   |   Building normalizer - found string feature columns to be encoded: "".
2020-11-20 22:19:44,161 studio.module        INFO       |   |   Successfully built normalizer of test data.
2020-11-20 22:19:44,162 studio.module        INFO       |   |   Successfully checked column types. Predicting.
2020-11-20 22:19:44,162 studio.core          INFO       |   |   BaseLearner._apply_normalize - Start:
2020-11-20 22:19:44,162 studio.core          INFO       |   |   |   Applying feature normalization - Start:
2020-11-20 22:19:44,162 studio.module        INFO       |   |   |   |   Start to execute normalizer.transform with column_list: "age,fnlwgt,education,education-num,marital-status,relationship,race,sex,capital-gain,capital-loss,hours-per-week".
2020-11-20 22:19:44,162 studio.module        INFO       |   |   |   |   Columns of input DataFrame: 11
2020-11-20 22:19:44,162 studio.module        INFO       |   |   |   |   Columns to be transformed: 11
2020-11-20 22:19:44,162 studio.module        INFO       |   |   |   |   Columns to be encoded: 11
2020-11-20 22:19:44,162 studio.module        INFO       |   |   |   |   Transform with label column income.
2020-11-20 22:19:44,162 studio.core          INFO       |   |   |   |   Normalizer._transform_numeric_feature_columns - Start:
2020-11-20 22:19:44,174 studio.module        INFO       |   |   |   |   |   Successfully encoded 11 numeric feature columns.
2020-11-20 22:19:44,175 studio.core          INFO       |   |   |   |   Normalizer._transform_numeric_feature_columns - End with 0.0123s elapsed.
2020-11-20 22:19:44,175 studio.module        INFO       |   |   |   |   Construct train set complete.
2020-11-20 22:19:44,175 studio.core          INFO       |   |   |   Applying feature normalization - End with 0.0130s elapsed.
2020-11-20 22:19:44,175 studio.core          INFO       |   |   BaseLearner._apply_normalize - End with 0.0131s elapsed.
2020-11-20 22:19:44,175 studio.core          INFO       |   |   BaseLearner._predict - Start:
2020-11-20 22:19:44,175 studio.core          INFO       |   |   |   Predicting probability - Start:
2020-11-20 22:19:44,237 studio.core          INFO       |   |   |   Predicting probability - End with 0.0621s elapsed.
2020-11-20 22:19:44,237 studio.core          INFO       |   |   |   calculating argmax(Probability) - Start:
2020-11-20 22:19:44,238 studio.core          INFO       |   |   |   calculating argmax(Probability) - End with 0.0001s elapsed.
2020-11-20 22:19:44,238 studio.core          INFO       |   |   BaseLearner._predict - End with 0.0627s elapsed.
2020-11-20 22:19:44,238 studio.module        INFO       |   |   Successfully predicted.
2020-11-20 22:19:44,238 studio.module        INFO       |   |   Found 2 label classes in classes_ attribute.
2020-11-20 22:19:44,239 studio.module        INFO       |   |   Using 1 as probability column.
2020-11-20 22:19:44,243 studio.module        INFO       |   |   Binary Classification Model Scored Columns are: 
2020-11-20 22:19:44,243 studio.module        INFO       |   |   There are 2 score columns: "Binary Class Assigned Labels,Calibrated Score"
2020-11-20 22:19:44,243 studio.core          DEBUG      |   |   return:
2020-11-20 22:19:44,244 studio.core          DEBUG      |   |   |   [0] = <DataTable "Dataset" (9768 Rows, 14 Cols) at 0x00007F9F380F8C18>
2020-11-20 22:19:44,244 studio.core          INFO       |   ScoreModelModule.run - End with 0.0876s elapsed.
2020-11-20 22:19:44,244 studio.core          INFO       |   ModuleReflector._handle_output_ports - Start:
2020-11-20 22:19:44,244 studio.core          INFO       |   |   Handle output port "Scored dataset" - Start:
2020-11-20 22:19:44,244 studio.modulehost    INFO       |   |   |   Data type: Dataset
2020-11-20 22:19:44,244 studio.modulehost    INFO       |   |   |   Create directory: '/tmp/tmp3oxa0ckd'
2020-11-20 22:19:44,246 studio.core          INFO       |   |   |   Create file 'data.dataset.parquet' via DataTableDatasetHandler - Start:
2020-11-20 22:19:44,246 studio.modulehost    INFO       |   |   |   |   Write DataTable into Dataset
2020-11-20 22:19:44,247 studio.core          INFO       |   |   |   |   Write pickle file 'data.dataset' - Start:
2020-11-20 22:19:44,247 studio.core          INFO       |   |   |   |   Write pickle file 'data.dataset' - End with 0.0003s elapsed.
2020-11-20 22:19:44,247 studio.core          INFO       |   |   |   |   Write to parquet file 'data.dataset.parquet'. Rows: 9768, Columns: 14. - Start:
/azureml-envs/azureml_65af40e73c072fae369d0c087f7671ca/lib/python3.6/site-packages/azureml/studio/core/io/data_frame_utils.py:78: FutureWarning: the 'fname'' keyword is deprecated, use 'path' instead
  allow_truncated_timestamps=True,
2020-11-20 22:19:44,261 studio.core          INFO       |   |   |   |   Write to parquet file 'data.dataset.parquet'. Rows: 9768, Columns: 14. - End with 0.0141s elapsed.
2020-11-20 22:19:44,262 studio.core          INFO       |   |   |   Create file 'data.dataset.parquet' via DataTableDatasetHandler - End with 0.0151s elapsed.
2020-11-20 22:19:44,262 studio.core          INFO       |   |   |   Create sidecar file 'data.schema' - Start:
2020-11-20 22:19:44,262 studio.core          INFO       |   |   |   Create sidecar file 'data.schema' - End with 0.0006s elapsed.
2020-11-20 22:19:44,263 studio.core          INFO       |   |   |   Create sidecar file 'data.visualization' - Start:
2020-11-20 22:19:44,374 studio.core          INFO       |   |   |   Create sidecar file 'data.visualization' - End with 0.1111s elapsed.
2020-11-20 22:19:44,374 studio.core          INFO       |   |   |   Create sidecar file 'data.metadata' - Start:
2020-11-20 22:19:44,374 studio.core          INFO       |   |   |   Create sidecar file 'data.metadata' - End with 0.0003s elapsed.
2020-11-20 22:19:44,379 studio.common        INFO       |   |   |   Writing meta successfully, datatype=DataTypes.DATASET
2020-11-20 22:19:44,379 studio.core          INFO       |   |   |   Create data type file 'data_type.json' - Start:
2020-11-20 22:19:44,380 studio.core          INFO       |   |   |   Create data type file 'data_type.json' - End with 0.0004s elapsed.
2020-11-20 22:19:44,380 studio.core          INFO       |   |   Handle output port "Scored dataset" - End with 0.1356s elapsed.
2020-11-20 22:19:44,380 studio.core          INFO       |   ModuleReflector._handle_output_ports - End with 0.1358s elapsed.
2020-11-20 22:19:44,380 studio.core          INFO       |   ModuleStatistics.save_to_azureml - Start:
2020-11-20 22:19:44,766 studio.core          INFO       |   ModuleStatistics.save_to_azureml - End with 0.3865s elapsed.
2020-11-20 22:19:44,767 studio.core          INFO       execute_with_cli - End with 3.2704s elapsed.
Starting the daemon thread to refresh tokens in background for process with pid = 101


[2020-11-20T22:19:44.780783] The experiment completed successfully. Finalizing run...
Cleaning up all outstanding Run operations, waiting 900.0 seconds
2 items cleaning up...
Cleanup took 0.1646883487701416 seconds
Enter __exit__ of DatasetContextManager
Unmounting /tmp/tmpz6nw9_hr.
Finishing unmounting /tmp/tmpz6nw9_hr.
Unmounting /tmp/tmpsr_c8lwa.
Finishing unmounting /tmp/tmpsr_c8lwa.
Uploading output 'Scored_dataset'.
Exit __exit__ of DatasetContextManager
[2020-11-20T22:19:46.654341] Finished context manager injector.
2020/11/20 22:19:53 Attempt 1 of http call to http://10.0.0.4:16384/sendlogstoartifacts/status
2020/11/20 22:19:53 Process Exiting with Code:  0
