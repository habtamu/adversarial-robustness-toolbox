{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"border: none\" align=\"center\">\n",
    "   <tr style=\"border: none\">\n",
    "      <th style=\"border: none\"><font face=\"verdana\" size=\"4\" color=\"black\"><b>  EXP:1 Model Train and Evaluation: ensemble learning  </b></font></font></th>\n",
    "   </tr> \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we demonstrate Model training and adversarial training using ART on the IRIS dataset.\n",
    "\n",
    "Sensitivity to training set details:\n",
    "https://nbviewer.jupyter.org/github/Azure/azureml-examples/blob/main/notebooks/train-lightgbm-local.ipynb\n",
    "\n",
    "\n",
    "## Contents\n",
    "\n",
    "1.\t[Load prereqs and data](#prereqs)\n",
    "2.  [Data scale, Train and evaluate a baseline classifier](#classifier)\n",
    "3.  [Adversarially train a robust classifier](#adv_training)\n",
    "4.\t[Evaluate the robust classifier](#evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"prereqs\"></a>\n",
    "## 1. Load prereqs and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])?  y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-24T23:41:32+01:00\n",
      "\n",
      "CPython 3.8.3\n",
      "IPython 7.19.0\n",
      "\n",
      "compiler   : MSC v.1916 64 bit (AMD64)\n",
      "system     : Windows\n",
      "release    : 7\n",
      "machine    : AMD64\n",
      "processor  : Intel64 Family 6 Model 37 Stepping 5, GenuineIntel\n",
      "CPU cores  : 4\n",
      "interpreter: 64bit\n"
     ]
    }
   ],
   "source": [
    "%watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization:\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# import warnings filter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# ignore all future warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Habtamu desalegn \n",
      "last updated: 2020-11-24 \n",
      "\n",
      "CPython 3.8.3\n",
      "IPython 7.19.0\n",
      "\n",
      "numpy 1.19.4\n",
      "pandas 1.1.3\n",
      "scipy 1.5.3\n",
      "matplotlib 3.3.3\n",
      "sklearn 0.23.2\n",
      "mlxtend 0.17.3\n"
     ]
    }
   ],
   "source": [
    "%reload_ext watermark\n",
    "%watermark  -d -u -a \"Habtamu desalegn\" -v -p numpy,pandas,scipy,matplotlib,sklearn,mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading the Libraries and Dependencies:\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import Image\n",
    "from typing import Tuple\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the IRIS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width      species\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COLUMNS = [\"sepal_length\",\"sepal_width\",\"petal_length\",\"petal_width\",\"species\"]\n",
    "PATH = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "df = pd.read_csv(PATH, header=None, index_col=None, names = COLUMNS)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df.loc[:,'species'] = le.fit_transform(df.loc[:,'species'].values)\n",
    "\n",
    "df.to_csv(\"data/iris_transformed.csv\",sep=',',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width  species\n",
       "0           5.1          3.5           1.4          0.2        0\n",
       "1           4.9          3.0           1.4          0.2        0\n",
       "2           4.7          3.2           1.3          0.2        0\n",
       "3           4.6          3.1           1.5          0.2        0\n",
       "4           5.0          3.6           1.4          0.2        0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"species\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>species</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sepal_length  sepal_width  petal_length  petal_width\n",
       "species                                                      \n",
       "0                  50           50            50           50\n",
       "1                  50           50            50           50\n",
       "2                  50           50            50           50"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# balanced data\n",
    "df.groupby(['species']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature , Lable\n",
    "X = df.drop('species', axis=1).values\n",
    "y = df['species'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=42,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (105, 4)\n",
      "y_train.shape: (105,)\n",
      "X_test.shape: (45, 4)\n",
      "y_test.shape: (45,)\n"
     ]
    }
   ],
   "source": [
    "print(f'X_train.shape: {X_train.shape}')\n",
    "print(f'y_train.shape: {y_train.shape}')\n",
    "print(f'X_test.shape: {X_test.shape}')\n",
    "print(f'y_test.shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"classifier\"></a>\n",
    "## 2. Preprocess ,Train and Evaluate a classifier\n",
    "\n",
    "1. [Data Scaling](#2_1)\n",
    "2. [Model Train and Evaluation: ensemble learning](#2_2)\n",
    "3. [Evaluate the model](#2_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2_1\"></a>\n",
    "### 1. Data Scaling\n",
    "\n",
    "Bringing features onto the same scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def preprocess_minmax(X_train: np.ndarray, X_test: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Normalization -- Min-max scaling\n",
    "\n",
    "    Scales `X_train` to [0, 1] , `X_test` to [0, 1]\n",
    "\n",
    "    :param X_train: Data instances.\n",
    "    :param X_test: Data instances.\n",
    "    :return: Rescaled values of `X_train`, `X_test`.\n",
    "    \"\"\"\n",
    "    \n",
    "    # normalize\n",
    "    #print('normalized:', (ex - ex.min()) / (ex.max() - ex.min()))\n",
    "    \n",
    "    mms = MinMaxScaler()\n",
    "    X_train_norm = mms.fit_transform(X_train)\n",
    "    X_test_norm = mms.transform(X_test)\n",
    "    \n",
    "    return X_train_norm, X_test_norm\n",
    "\n",
    "def preprocess_standard(X_train: np.ndarray, X_test: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Standard scaling: Gaussian with zero mean and unit variance\n",
    "\n",
    "    Scales `X_train` to [0, 1] , `X_test` to [0, 1]\n",
    "\n",
    "    :param x: Data instances.\n",
    "    :param y: Labels.\n",
    "    :return: Rescaled values of `x`, `y`.\n",
    "    \"\"\"\n",
    "    \n",
    "    stdsc = StandardScaler()\n",
    "    X_train_std = stdsc.fit_transform(X_train)\n",
    "    X_test_std = stdsc.transform(X_test)\n",
    "    \n",
    "    return X_train_std, X_test_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess - Training and testing set\n",
    "### standard\n",
    "#(X_train, X_test) = preprocess_standard(X_train[:,[0,1]], X_test[:,[0,1]])    #  0=sepal length, 1=sepal width\n",
    "(X_train, X_test) = preprocess_standard(X_train[:,2:], X_test[:,2:])           #  2=petal length, 3=petal width\n",
    "\n",
    "### normalize\n",
    "#(X_train, X_test) = preprocess_minmax(X_train[:,[0,1]], X_test[:,[0,1]])     #  0=sepal length, 1=sepal width\n",
    "#(X_train, X_test) = preprocess_minmax(X_train[:,2:], X_test[:,2:])           #  2=petal length, 3=petal width\n",
    "\n",
    "### with out normalization\n",
    "#(X_train, X_test) = X_train[:,[0,1]], X_test[:,[0,1]]      #  0=sepal length, 1=sepal width\n",
    "#(X_train, X_test) = X_train[:,2:], X_test[:,2:]            #  2=petal length, 3=petal width\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105, 2)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.10014569, -0.32149987],\n",
       "       [ 0.71771076,  0.35364985],\n",
       "       [ 0.95138404,  0.75873969],\n",
       "       [ 0.30878254,  0.21861991],\n",
       "       [ 1.30189395,  1.7039493 ]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 2, 1, 2, 1, 2, 1, 0, 2, 1, 0, 0, 0, 1, 2, 0, 0, 0, 1, 0, 1,\n",
       "       2, 0, 1, 2, 0, 2, 2, 1, 1, 2, 1, 0, 1, 2, 0, 0, 1, 1, 0, 2, 0, 0,\n",
       "       1, 1, 2, 1, 2, 2, 1, 0, 0, 2, 2, 0, 0, 0, 1, 2, 0, 2, 2, 0, 1, 1,\n",
       "       2, 1, 2, 0, 2, 1, 2, 1, 1, 1, 0, 1, 1, 0, 1, 2, 2, 0, 1, 2, 2, 0,\n",
       "       2, 0, 1, 2, 2, 1, 2, 1, 1, 2, 2, 0, 1, 2, 0, 1, 2])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2_2_1\"></a>\n",
    "### 2.1 Model Training: Fit a Ensemble Methods via scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: BaggingClassifier(base_estimator=DecisionTreeClassifier(criterion='entropy',\n",
      "                                                        max_depth=32,\n",
      "                                                        random_state=42),\n",
      "                  n_jobs=1, oob_score=True, random_state=42)\n",
      "OOB Accuracy: 0.93\n",
      "Test Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Ref: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "# Ref: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "tree  = DecisionTreeClassifier(criterion='entropy', max_depth=32, min_samples_leaf=1, random_state=42)\n",
    "\n",
    "model = BaggingClassifier(base_estimator=tree,\n",
    "                        n_estimators=10,\n",
    "                        oob_score=True,\n",
    "                        bootstrap=True,\n",
    "                        bootstrap_features=False,\n",
    "                        n_jobs=1,\n",
    "                        random_state=42)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(f'model: {model}')\n",
    "print(\"OOB Accuracy: %0.2f\" % model.oob_score_)\n",
    "print(\"Test Accuracy: %0.2f\" % model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2_3\"></a>\n",
    "### Evaluate the model\n",
    "\n",
    "Looking at different performance evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: [1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0 0 0 1 0 0 2 1\n",
      " 0 0 0 2 1 1 0 0]\n",
      "y_true: [1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0 0 0 1 0 0 2 1\n",
      " 0 0 0 2 1 1 0 0]\n",
      "Misclassified examples:0\n",
      "confusion matrix:\n",
      " [[19  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  0 13]]\n",
      "Accuracy: 1.0\n",
      "\n",
      "[Precision]\n",
      "Individual: 1.00, 1.00, 1.00\n",
      "micro: 1.0\n",
      "macro: 1.0\n",
      "\n",
      "[Recall]\n",
      "Individual: 1.00, 1.00, 1.00\n",
      "micro: 1.0\n",
      "macro: 1.0\n",
      "\n",
      "[F1-score]\n",
      "Individual: 1.00, 1.00, 1.00\n",
      "micro: 1.0\n",
      "macro: 1.0\n",
      "\n",
      "[ROC AUC]\n",
      "macro: 1.0\n",
      "\n",
      "classification_report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       1.00      1.00      1.00        13\n",
      "           2       1.00      1.00      1.00        13\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n",
      "\n",
      "X_test:\n",
      " [[ 0.48403749 -0.05143998]\n",
      " [-1.26851205 -1.26670948]\n",
      " [ 1.76924049  1.43388941]\n",
      " [ 0.36720086  0.35364985]\n",
      " [ 0.54245581  0.21861991]]\n",
      "\n",
      "class probabilities:\n",
      " [[0.  1.  0. ]\n",
      " [1.  0.  0. ]\n",
      " [0.  0.  1. ]\n",
      " [0.  1.  0. ]\n",
      " [0.  0.9 0.1]]\n",
      "\n",
      "Predicting classes: [1 0 2 1 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "def multiclass_roc_auc_score(y_test, y_pred, average='macro'):\n",
    "    lb = LabelBinarizer()\n",
    "    y_test_bin = lb.fit_transform(y_test)\n",
    "    y_pred_bin = lb.fit_transform(y_pred)\n",
    "    \n",
    "    return metrics.roc_auc_score(y_test_bin, y_pred_bin, average)\n",
    "\n",
    "# using predict_proba\n",
    "# y_proba  = model.predict_proba(X_test)\n",
    "#print(f\"class probabilities:\\n {y_proba }\")\n",
    "# y_pred = y_proba.argmax(axis=1)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"prediction: {y_pred}\")\n",
    "print(f\"y_true: {y_test}\")\n",
    "print(f'Misclassified examples:{(y_test != y_pred).sum()}')\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_mat = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(f\"confusion matrix:\\n {conf_mat}\")\n",
    "\n",
    "# Accuracy\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Precision\n",
    "print('\\n[Precision]')\n",
    "precision = metrics.precision_score(y_test, y_pred, average=None)\n",
    "print(f'Individual: {precision[0]:.2f}, {precision[1]:.2f}, {precision[2]:.2f}')\n",
    "precision = metrics.precision_score(y_test, y_pred, average='micro')\n",
    "print(f\"micro: {precision}\")\n",
    "precision = metrics.precision_score(y_test, y_pred, average='macro')\n",
    "print(f\"macro: {precision}\")\n",
    "\n",
    "# Recall\n",
    "print('\\n[Recall]')\n",
    "recall = metrics.recall_score(y_test, y_pred, average=None)\n",
    "print(f'Individual: {recall[0]:.2f}, {recall[1]:.2f}, {recall[2]:.2f}')\n",
    "recall = metrics.recall_score(y_test, y_pred, average='micro')\n",
    "print(f\"micro: {recall}\")\n",
    "recall = metrics.recall_score(y_test, y_pred, average='macro')\n",
    "print(f\"macro: {recall}\")\n",
    "\n",
    "# F1\n",
    "print('\\n[F1-score]')\n",
    "f1 = metrics.f1_score(y_test, y_pred, average=None)\n",
    "print(f'Individual: {f1[0]:.2f}, {f1[1]:.2f}, {f1[2]:.2f}')\n",
    "f1 = metrics.f1_score(y_test, y_pred, average='micro')\n",
    "print(f\"micro: {f1}\")\n",
    "f1 = metrics.f1_score(y_test, y_pred, average='macro')\n",
    "print(f\"macro: {f1}\")\n",
    "\n",
    "# AUC\n",
    "print('\\n[ROC AUC]')\n",
    "auc = multiclass_roc_auc_score(y_test, y_pred, average='macro')\n",
    "print(f\"macro: {auc}\")\n",
    "\n",
    "# classification_report\n",
    "print(f\"\\nclassification_report:\\n {metrics.classification_report(y_test, y_pred)}\")\n",
    "\n",
    "# Predicting classes and class probabilities\n",
    "print(f\"\\nX_test:\\n {X_test[0:5,:]}\")\n",
    "print(f\"\\nclass probabilities:\\n {model.predict_proba(X_test[0:5,:])}\")\n",
    "print(f\"\\nPredicting classes: {model.predict(X_test[0:5,:])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 180x180 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(2.5, 2.5))\n",
    "ax.matshow(conf_mat, cmap=plt.cm.Blues, alpha=0.3)\n",
    "for i in range(conf_mat.shape[0]):\n",
    "    for j in range(conf_mat.shape[1]):\n",
    "        ax.text(x=j, y=i, s=conf_mat[i, j], va='center', ha='center')\n",
    "\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Adversarial-Robustness-Toolbox for scikit-learn Ensemble Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
